{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C:\\\\gab\\\\train.csv',\n",
    "                   sep=',', \n",
    "                   header=None, \n",
    "                   names=['article', 'label'],\n",
    "                   encoding='ISO-8859-1')\n",
    "df1 = pd.read_csv('C:\\\\gab\\\\test.csv',\n",
    "                   sep=',', \n",
    "                   header=None, \n",
    "                   names=['article', 'label'],\n",
    "                   encoding='ISO-8859-1')\n",
    "df2 = pd.read_csv('C:\\\\gab\\\\dev.csv',\n",
    "                   sep=',', \n",
    "                   header=None, \n",
    "                   names=['article', 'label'],\n",
    "                   encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19093, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4133, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4052, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What's wrong with that? It's History you know....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Switzerland, I'm guessing ? if so, an outlier ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are they selling ? Are? they trying to? m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://bit.do/b7ndm: Dr. Paul Powers is back i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@support? the prompt for browser notifications...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I really hope against all hope, that Sessions ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Italy: Mass Deportation Of Migrants May Start ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A Sith Lord's level of mental illness...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I don't endorse any of the links on this site,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Maybe it's me being a bit jaded because I'm in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  label\n",
       "0  What's wrong with that? It's History you know....      0\n",
       "1  Switzerland, I'm guessing ? if so, an outlier ...      0\n",
       "2  What are they selling ? Are? they trying to? m...      0\n",
       "3  http://bit.do/b7ndm: Dr. Paul Powers is back i...      0\n",
       "4  @support? the prompt for browser notifications...      0\n",
       "5  I really hope against all hope, that Sessions ...      0\n",
       "6  Italy: Mass Deportation Of Migrants May Start ...      0\n",
       "7           A Sith Lord's level of mental illness...      0\n",
       "8  I don't endorse any of the links on this site,...      0\n",
       "9  Maybe it's me being a bit jaded because I'm in...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please go to Dane's website at www.geoengineer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anybody else sick of online product launch vid...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hold on #GabFam I am just getting warm, blowin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Democrat Party exists for the media's globalis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Relegion of open and 'lawful' child sexual abu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.bitchute.com/video/not1pbGQA9uE/  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Can't wait to see former Tory MP's crying woe ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>There's a phrase being used right now that I t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://rickyrescue.com/florida-state-fire-cer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Look, gun grabbers. I have wasted a lot of bre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  label\n",
       "0  Please go to Dane's website at www.geoengineer...      0\n",
       "1  Anybody else sick of online product launch vid...      1\n",
       "2  Hold on #GabFam I am just getting warm, blowin...      0\n",
       "3  Democrat Party exists for the media's globalis...      0\n",
       "4  Relegion of open and 'lawful' child sexual abu...      1\n",
       "5  https://www.bitchute.com/video/not1pbGQA9uE/  ...      0\n",
       "6  Can't wait to see former Tory MP's crying woe ...      0\n",
       "7  There's a phrase being used right now that I t...      0\n",
       "8  https://rickyrescue.com/florida-state-fire-cer...      0\n",
       "9  Look, gun grabbers. I have wasted a lot of bre...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lewis's brother, Charles, King of Italy (also ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I hope the person who invented wallpaper is ex...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Same reason we never told you about the \"Holoc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anamorph - A game of perspective. The fun of a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes he should he is working against the Presid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What does ¡®acting like Californians¡¯ mean?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I guess I'll do a small rundown from the stuff...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>He is still ignoring the communists... except ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Radio Derb Transcript Up: Explaining Discharge...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>found it.    http://www.whsports.se    channel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  label\n",
       "0  Lewis's brother, Charles, King of Italy (also ...      0\n",
       "1  I hope the person who invented wallpaper is ex...      0\n",
       "2  Same reason we never told you about the \"Holoc...      0\n",
       "3  Anamorph - A game of perspective. The fun of a...      0\n",
       "4  Yes he should he is working against the Presid...      0\n",
       "5       What does ¡®acting like Californians¡¯ mean?      0\n",
       "6  I guess I'll do a small rundown from the stuff...      0\n",
       "7  He is still ignoring the communists... except ...      0\n",
       "8  Radio Derb Transcript Up: Explaining Discharge...      0\n",
       "9  found it.    http://www.whsports.se    channel...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0  16898\n",
       "1   2195"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "label_counts = pd.DataFrame(df['label'].value_counts())\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0   3658\n",
       "1    475"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = pd.DataFrame(df1['label'].value_counts())\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0   3577\n",
       "1    475"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = pd.DataFrame(df2['label'].value_counts())\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "label_values = list(label_counts.index)\n",
    "order = list(pd.DataFrame(df['label'].value_counts()).index)\n",
    "label_values = [l for _,l in sorted(zip(order, label_values))]\n",
    "\n",
    "label_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "label_values = list(label_counts.index)\n",
    "order = list(pd.DataFrame(df1['label'].value_counts()).index)\n",
    "label_values = [l for _,l in sorted(zip(order, label_values))]\n",
    "\n",
    "label_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "label_values = list(label_counts.index)\n",
    "order = list(pd.DataFrame(df2['label'].value_counts()).index)\n",
    "label_values = [l for _,l in sorted(zip(order, label_values))]\n",
    "\n",
    "label_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['article'].values\n",
    "labels = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts1 = df1['article'].values\n",
    "labels1 = df1['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts2 = df2['article'].values\n",
    "labels2 = df2['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "894\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text_lengths = [len(texts[i].split()) for i in range(len(texts))]\n",
    "print(min(text_lengths))\n",
    "print(max(text_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "353\n"
     ]
    }
   ],
   "source": [
    "text_lengths1 = [len(texts1[i].split()) for i in range(len(texts1))]\n",
    "print(min(text_lengths1))\n",
    "print(max(text_lengths1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "815\n"
     ]
    }
   ],
   "source": [
    "text_lengths2 = [len(texts2[i].split()) for i in range(len(texts2))]\n",
    "print(min(text_lengths2))\n",
    "print(max(text_lengths2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1 for i in range(len(text_lengths)) if text_lengths[i] >= 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1 for i in range(len(text_lengths1)) if text_lengths1[i] >= 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1 for i in range(len(text_lengths2)) if text_lengths2[i] >= 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:  What's wrong with that? It's History you know. Mary Beard told me so and she has a vagina from Oxford. \n",
      "\n",
      "Tokenized Text:  ['what', \"'\", 's', 'wrong', 'with', 'that', '?', 'it', \"'\", 's', 'history', 'you', 'know', '.', 'mary', 'beard', 'told', 'me', 'so', 'and', 'she', 'has', 'a', 'va', '##gina', 'from', 'oxford', '.'] \n",
      "\n",
      "Token IDs:  [2054, 1005, 1055, 3308, 2007, 2008, 1029, 2009, 1005, 1055, 2381, 2017, 2113, 1012, 2984, 10154, 2409, 2033, 2061, 1998, 2016, 2038, 1037, 12436, 20876, 2013, 4345, 1012]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n",
    "\n",
    "print('Original Text: ', texts[0], '\\n')\n",
    "print('Tokenized Text: ', tokenizer.tokenize(texts[0]), '\\n')\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(texts[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:  Please go to Dane's website at www.geoengineering.org and educate yourselves on this global crime, it's your children's, and their children's lives at risk. Thank you.  \n",
      "\n",
      "Tokenized Text:  ['please', 'go', 'to', 'dane', \"'\", 's', 'website', 'at', 'www', '.', 'geo', '##eng', '##ine', '##ering', '.', 'org', 'and', 'educate', 'yourselves', 'on', 'this', 'global', 'crime', ',', 'it', \"'\", 's', 'your', 'children', \"'\", 's', ',', 'and', 'their', 'children', \"'\", 's', 'lives', 'at', 'risk', '.', 'thank', 'you', '.'] \n",
      "\n",
      "Token IDs:  [3531, 2175, 2000, 14569, 1005, 1055, 4037, 2012, 7479, 1012, 20248, 13159, 3170, 7999, 1012, 8917, 1998, 16957, 25035, 2006, 2023, 3795, 4126, 1010, 2009, 1005, 1055, 2115, 2336, 1005, 1055, 1010, 1998, 2037, 2336, 1005, 1055, 3268, 2012, 3891, 1012, 4067, 2017, 1012]\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n",
    "\n",
    "print('Original Text: ', texts1[0], '\\n')\n",
    "print('Tokenized Text: ', tokenizer.tokenize(texts1[0]), '\\n')\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(texts1[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:  Lewis's brother, Charles, King of Italy (also known as Charles the Fat, as he was an obese slob) sat by idly while all this was happening and did nothing.? The Pope gave him the title of Emperor, hoping he this would spur him to action, but still he did nothing.? When Lewis died, Charles became ruler over his lands as well.? Messengers hastened to him, begging him to come save his people from d... \n",
      "\n",
      "Tokenized Text:  ['lewis', \"'\", 's', 'brother', ',', 'charles', ',', 'king', 'of', 'italy', '(', 'also', 'known', 'as', 'charles', 'the', 'fat', ',', 'as', 'he', 'was', 'an', 'obe', '##se', 'sl', '##ob', ')', 'sat', 'by', 'id', '##ly', 'while', 'all', 'this', 'was', 'happening', 'and', 'did', 'nothing', '.', '?', 'the', 'pope', 'gave', 'him', 'the', 'title', 'of', 'emperor', ',', 'hoping', 'he', 'this', 'would', 'spur', 'him', 'to', 'action', ',', 'but', 'still', 'he', 'did', 'nothing', '.', '?', 'when', 'lewis', 'died', ',', 'charles', 'became', 'ruler', 'over', 'his', 'lands', 'as', 'well', '.', '?', 'messengers', 'haste', '##ned', 'to', 'him', ',', 'begging', 'him', 'to', 'come', 'save', 'his', 'people', 'from', 'd', '.', '.', '.'] \n",
      "\n",
      "Token IDs:  [4572, 1005, 1055, 2567, 1010, 2798, 1010, 2332, 1997, 3304, 1006, 2036, 2124, 2004, 2798, 1996, 6638, 1010, 2004, 2002, 2001, 2019, 15578, 3366, 22889, 16429, 1007, 2938, 2011, 8909, 2135, 2096, 2035, 2023, 2001, 6230, 1998, 2106, 2498, 1012, 1029, 1996, 4831, 2435, 2032, 1996, 2516, 1997, 3750, 1010, 5327, 2002, 2023, 2052, 12996, 2032, 2000, 2895, 1010, 2021, 2145, 2002, 2106, 2498, 1012, 1029, 2043, 4572, 2351, 1010, 2798, 2150, 7786, 2058, 2010, 4915, 2004, 2092, 1012, 1029, 28938, 24748, 7228, 2000, 2032, 1010, 12858, 2032, 2000, 2272, 3828, 2010, 2111, 2013, 1040, 1012, 1012, 1012]\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n",
    "\n",
    "print('Original Text: ', texts2[0], '\\n')\n",
    "print('Tokenized Text: ', tokenizer.tokenize(texts2[0]), '\\n')\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(texts2[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2143: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 2054,\n",
       " 1005,\n",
       " 1055,\n",
       " 3308,\n",
       " 2007,\n",
       " 2008,\n",
       " 1029,\n",
       " 2009,\n",
       " 1005,\n",
       " 1055,\n",
       " 2381,\n",
       " 2017,\n",
       " 2113,\n",
       " 1012,\n",
       " 2984,\n",
       " 10154,\n",
       " 2409,\n",
       " 2033,\n",
       " 2061,\n",
       " 1998,\n",
       " 2016,\n",
       " 2038,\n",
       " 1037,\n",
       " 12436,\n",
       " 20876,\n",
       " 2013,\n",
       " 4345,\n",
       " 1012,\n",
       " 102,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "text_ids = [tokenizer.encode(text, max_length=100, pad_to_max_length=True) for text in texts]\n",
    "\n",
    "text_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 3531,\n",
       " 2175,\n",
       " 2000,\n",
       " 14569,\n",
       " 1005,\n",
       " 1055,\n",
       " 4037,\n",
       " 2012,\n",
       " 7479,\n",
       " 1012,\n",
       " 20248,\n",
       " 13159,\n",
       " 3170,\n",
       " 7999,\n",
       " 1012,\n",
       " 8917,\n",
       " 1998,\n",
       " 16957,\n",
       " 25035,\n",
       " 2006,\n",
       " 2023,\n",
       " 3795,\n",
       " 4126,\n",
       " 1010,\n",
       " 2009,\n",
       " 1005,\n",
       " 1055,\n",
       " 2115,\n",
       " 2336,\n",
       " 1005,\n",
       " 1055,\n",
       " 1010,\n",
       " 1998,\n",
       " 2037,\n",
       " 2336,\n",
       " 1005,\n",
       " 1055,\n",
       " 3268,\n",
       " 2012,\n",
       " 3891,\n",
       " 1012,\n",
       " 4067,\n",
       " 2017,\n",
       " 1012,\n",
       " 102,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_ids1 = [tokenizer.encode(text, max_length=100, pad_to_max_length=True) for text in texts1]\n",
    "\n",
    "text_ids1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 4572,\n",
       " 1005,\n",
       " 1055,\n",
       " 2567,\n",
       " 1010,\n",
       " 2798,\n",
       " 1010,\n",
       " 2332,\n",
       " 1997,\n",
       " 3304,\n",
       " 1006,\n",
       " 2036,\n",
       " 2124,\n",
       " 2004,\n",
       " 2798,\n",
       " 1996,\n",
       " 6638,\n",
       " 1010,\n",
       " 2004,\n",
       " 2002,\n",
       " 2001,\n",
       " 2019,\n",
       " 15578,\n",
       " 3366,\n",
       " 22889,\n",
       " 16429,\n",
       " 1007,\n",
       " 2938,\n",
       " 2011,\n",
       " 8909,\n",
       " 2135,\n",
       " 2096,\n",
       " 2035,\n",
       " 2023,\n",
       " 2001,\n",
       " 6230,\n",
       " 1998,\n",
       " 2106,\n",
       " 2498,\n",
       " 1012,\n",
       " 1029,\n",
       " 1996,\n",
       " 4831,\n",
       " 2435,\n",
       " 2032,\n",
       " 1996,\n",
       " 2516,\n",
       " 1997,\n",
       " 3750,\n",
       " 1010,\n",
       " 5327,\n",
       " 2002,\n",
       " 2023,\n",
       " 2052,\n",
       " 12996,\n",
       " 2032,\n",
       " 2000,\n",
       " 2895,\n",
       " 1010,\n",
       " 2021,\n",
       " 2145,\n",
       " 2002,\n",
       " 2106,\n",
       " 2498,\n",
       " 1012,\n",
       " 1029,\n",
       " 2043,\n",
       " 4572,\n",
       " 2351,\n",
       " 1010,\n",
       " 2798,\n",
       " 2150,\n",
       " 7786,\n",
       " 2058,\n",
       " 2010,\n",
       " 4915,\n",
       " 2004,\n",
       " 2092,\n",
       " 1012,\n",
       " 1029,\n",
       " 28938,\n",
       " 24748,\n",
       " 7228,\n",
       " 2000,\n",
       " 2032,\n",
       " 1010,\n",
       " 12858,\n",
       " 2032,\n",
       " 2000,\n",
       " 2272,\n",
       " 3828,\n",
       " 2010,\n",
       " 2111,\n",
       " 2013,\n",
       " 1040,\n",
       " 1012,\n",
       " 1012,\n",
       " 1012,\n",
       " 102]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_ids2 = [tokenizer.encode(text, max_length=100, pad_to_max_length=True) for text in texts2]\n",
    "\n",
    "text_ids2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text_ids_lengths = [len(text_ids[i]) for i in range(len(text_ids))]\n",
    "print(min(text_ids_lengths))\n",
    "print(max(text_ids_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "text_ids_lengths1 = [len(text_ids1[i]) for i in range(len(text_ids1))]\n",
    "print(min(text_ids_lengths1))\n",
    "print(max(text_ids_lengths1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "text_ids_lengths2 = [len(text_ids2[i]) for i in range(len(text_ids2))]\n",
    "print(min(text_ids_lengths2))\n",
    "print(max(text_ids_lengths2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_masks = []\n",
    "for ids in text_ids:\n",
    "    masks = [int(id > 0) for id in ids]\n",
    "    att_masks.append(masks)\n",
    "    \n",
    "att_masks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_masks1 = []\n",
    "for ids in text_ids1:\n",
    "    masks = [int(id > 0) for id in ids]\n",
    "    att_masks1.append(masks)\n",
    "    \n",
    "att_masks1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_masks2 = []\n",
    "for ids in text_ids2:\n",
    "    masks = [int(id > 0) for id in ids]\n",
    "    att_masks2.append(masks)\n",
    "    \n",
    "att_masks2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#train_x, test_val_x, train_y, test_val_y = train_test_split(text_ids, labels, random_state=111, test_size=0.2)\n",
    "#train_m, test_val_m = train_test_split(att_masks, random_state=111, test_size=0.2)\n",
    "\n",
    "#test_x, val_x, test_y, val_y = train_test_split(test_val_x, test_val_y, random_state=111, test_size=0.5)\n",
    "#test_m, val_m = train_test_split(test_val_m, random_state=111, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = text_ids\n",
    "train_y = labels\n",
    "train_m = att_masks\n",
    "\n",
    "val_x = text_ids1\n",
    "val_y = labels1\n",
    "val_m = att_masks1\n",
    "\n",
    "test_x = text_ids2\n",
    "test_y = labels2\n",
    "test_m = att_masks2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19093, 100])\n",
      "torch.Size([4052, 100])\n",
      "torch.Size([4133, 100])\n",
      "torch.Size([19093])\n",
      "torch.Size([4052])\n",
      "torch.Size([4133])\n",
      "torch.Size([19093, 100])\n",
      "torch.Size([4052, 100])\n",
      "torch.Size([4133, 100])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "train_x = torch.tensor(train_x)\n",
    "test_x = torch.tensor(test_x)\n",
    "val_x = torch.tensor(val_x)\n",
    "train_y = torch.tensor(train_y)\n",
    "test_y = torch.tensor(test_y)\n",
    "val_y = torch.tensor(val_y)\n",
    "train_m = torch.tensor(train_m)\n",
    "test_m = torch.tensor(test_m)\n",
    "val_m = torch.tensor(val_m)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)\n",
    "print(val_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)\n",
    "print(val_y.shape)\n",
    "print(train_m.shape)\n",
    "print(test_m.shape)\n",
    "print(val_m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_data = TensorDataset(train_x, train_m, train_y)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "val_data = TensorDataset(val_x, val_m, val_y)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification, AdamW, DistilBertConfig\n",
    "\n",
    "num_labels = len(set(labels))\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels,\n",
    "                                                            output_attentions=False, output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 66955010 \n",
      " DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (4): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (5): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print('Number of trainable parameters:', count_parameters(model), '\\n', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['distilbert.embeddings.word_embeddings.weight',\n",
       " 'distilbert.embeddings.position_embeddings.weight',\n",
       " 'distilbert.embeddings.LayerNorm.weight',\n",
       " 'distilbert.embeddings.LayerNorm.bias',\n",
       " 'distilbert.transformer.layer.0.attention.q_lin.weight',\n",
       " 'distilbert.transformer.layer.0.attention.q_lin.bias',\n",
       " 'distilbert.transformer.layer.0.attention.k_lin.weight',\n",
       " 'distilbert.transformer.layer.0.attention.k_lin.bias',\n",
       " 'distilbert.transformer.layer.0.attention.v_lin.weight',\n",
       " 'distilbert.transformer.layer.0.attention.v_lin.bias',\n",
       " 'distilbert.transformer.layer.0.attention.out_lin.weight',\n",
       " 'distilbert.transformer.layer.0.attention.out_lin.bias',\n",
       " 'distilbert.transformer.layer.0.sa_layer_norm.weight',\n",
       " 'distilbert.transformer.layer.0.sa_layer_norm.bias',\n",
       " 'distilbert.transformer.layer.0.ffn.lin1.weight',\n",
       " 'distilbert.transformer.layer.0.ffn.lin1.bias',\n",
       " 'distilbert.transformer.layer.0.ffn.lin2.weight',\n",
       " 'distilbert.transformer.layer.0.ffn.lin2.bias',\n",
       " 'distilbert.transformer.layer.0.output_layer_norm.weight',\n",
       " 'distilbert.transformer.layer.0.output_layer_norm.bias',\n",
       " 'distilbert.transformer.layer.1.attention.q_lin.weight',\n",
       " 'distilbert.transformer.layer.1.attention.q_lin.bias',\n",
       " 'distilbert.transformer.layer.1.attention.k_lin.weight',\n",
       " 'distilbert.transformer.layer.1.attention.k_lin.bias',\n",
       " 'distilbert.transformer.layer.1.attention.v_lin.weight',\n",
       " 'distilbert.transformer.layer.1.attention.v_lin.bias',\n",
       " 'distilbert.transformer.layer.1.attention.out_lin.weight',\n",
       " 'distilbert.transformer.layer.1.attention.out_lin.bias',\n",
       " 'distilbert.transformer.layer.1.sa_layer_norm.weight',\n",
       " 'distilbert.transformer.layer.1.sa_layer_norm.bias',\n",
       " 'distilbert.transformer.layer.1.ffn.lin1.weight',\n",
       " 'distilbert.transformer.layer.1.ffn.lin1.bias',\n",
       " 'distilbert.transformer.layer.1.ffn.lin2.weight',\n",
       " 'distilbert.transformer.layer.1.ffn.lin2.bias',\n",
       " 'distilbert.transformer.layer.1.output_layer_norm.weight',\n",
       " 'distilbert.transformer.layer.1.output_layer_norm.bias',\n",
       " 'distilbert.transformer.layer.2.attention.q_lin.weight',\n",
       " 'distilbert.transformer.layer.2.attention.q_lin.bias',\n",
       " 'distilbert.transformer.layer.2.attention.k_lin.weight',\n",
       " 'distilbert.transformer.layer.2.attention.k_lin.bias',\n",
       " 'distilbert.transformer.layer.2.attention.v_lin.weight',\n",
       " 'distilbert.transformer.layer.2.attention.v_lin.bias',\n",
       " 'distilbert.transformer.layer.2.attention.out_lin.weight',\n",
       " 'distilbert.transformer.layer.2.attention.out_lin.bias',\n",
       " 'distilbert.transformer.layer.2.sa_layer_norm.weight',\n",
       " 'distilbert.transformer.layer.2.sa_layer_norm.bias',\n",
       " 'distilbert.transformer.layer.2.ffn.lin1.weight',\n",
       " 'distilbert.transformer.layer.2.ffn.lin1.bias',\n",
       " 'distilbert.transformer.layer.2.ffn.lin2.weight',\n",
       " 'distilbert.transformer.layer.2.ffn.lin2.bias',\n",
       " 'distilbert.transformer.layer.2.output_layer_norm.weight',\n",
       " 'distilbert.transformer.layer.2.output_layer_norm.bias',\n",
       " 'distilbert.transformer.layer.3.attention.q_lin.weight',\n",
       " 'distilbert.transformer.layer.3.attention.q_lin.bias',\n",
       " 'distilbert.transformer.layer.3.attention.k_lin.weight',\n",
       " 'distilbert.transformer.layer.3.attention.k_lin.bias',\n",
       " 'distilbert.transformer.layer.3.attention.v_lin.weight',\n",
       " 'distilbert.transformer.layer.3.attention.v_lin.bias',\n",
       " 'distilbert.transformer.layer.3.attention.out_lin.weight',\n",
       " 'distilbert.transformer.layer.3.attention.out_lin.bias',\n",
       " 'distilbert.transformer.layer.3.sa_layer_norm.weight',\n",
       " 'distilbert.transformer.layer.3.sa_layer_norm.bias',\n",
       " 'distilbert.transformer.layer.3.ffn.lin1.weight',\n",
       " 'distilbert.transformer.layer.3.ffn.lin1.bias',\n",
       " 'distilbert.transformer.layer.3.ffn.lin2.weight',\n",
       " 'distilbert.transformer.layer.3.ffn.lin2.bias',\n",
       " 'distilbert.transformer.layer.3.output_layer_norm.weight',\n",
       " 'distilbert.transformer.layer.3.output_layer_norm.bias',\n",
       " 'distilbert.transformer.layer.4.attention.q_lin.weight',\n",
       " 'distilbert.transformer.layer.4.attention.q_lin.bias',\n",
       " 'distilbert.transformer.layer.4.attention.k_lin.weight',\n",
       " 'distilbert.transformer.layer.4.attention.k_lin.bias',\n",
       " 'distilbert.transformer.layer.4.attention.v_lin.weight',\n",
       " 'distilbert.transformer.layer.4.attention.v_lin.bias',\n",
       " 'distilbert.transformer.layer.4.attention.out_lin.weight',\n",
       " 'distilbert.transformer.layer.4.attention.out_lin.bias',\n",
       " 'distilbert.transformer.layer.4.sa_layer_norm.weight',\n",
       " 'distilbert.transformer.layer.4.sa_layer_norm.bias',\n",
       " 'distilbert.transformer.layer.4.ffn.lin1.weight',\n",
       " 'distilbert.transformer.layer.4.ffn.lin1.bias',\n",
       " 'distilbert.transformer.layer.4.ffn.lin2.weight',\n",
       " 'distilbert.transformer.layer.4.ffn.lin2.bias',\n",
       " 'distilbert.transformer.layer.4.output_layer_norm.weight',\n",
       " 'distilbert.transformer.layer.4.output_layer_norm.bias',\n",
       " 'distilbert.transformer.layer.5.attention.q_lin.weight',\n",
       " 'distilbert.transformer.layer.5.attention.q_lin.bias',\n",
       " 'distilbert.transformer.layer.5.attention.k_lin.weight',\n",
       " 'distilbert.transformer.layer.5.attention.k_lin.bias',\n",
       " 'distilbert.transformer.layer.5.attention.v_lin.weight',\n",
       " 'distilbert.transformer.layer.5.attention.v_lin.bias',\n",
       " 'distilbert.transformer.layer.5.attention.out_lin.weight',\n",
       " 'distilbert.transformer.layer.5.attention.out_lin.bias',\n",
       " 'distilbert.transformer.layer.5.sa_layer_norm.weight',\n",
       " 'distilbert.transformer.layer.5.sa_layer_norm.bias',\n",
       " 'distilbert.transformer.layer.5.ffn.lin1.weight',\n",
       " 'distilbert.transformer.layer.5.ffn.lin1.bias',\n",
       " 'distilbert.transformer.layer.5.ffn.lin2.weight',\n",
       " 'distilbert.transformer.layer.5.ffn.lin2.bias',\n",
       " 'distilbert.transformer.layer.5.output_layer_norm.weight',\n",
       " 'distilbert.transformer.layer.5.output_layer_norm.bias',\n",
       " 'pre_classifier.weight',\n",
       " 'pre_classifier.bias',\n",
       " 'classifier.weight',\n",
       " 'classifier.bias']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n for n, p in model.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "adam_epsilon = 1e-8\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.2},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=adam_epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "num_epochs = 3\n",
    "total_steps = len(train_dataloader) * num_epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "seed_val = 111\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss after itaration 1: 0.277273\n",
      "Validation loss after itaration 1: 0.234386\n",
      "Time: 74m 39s\n",
      "\n",
      "Train loss after itaration 2: 0.219127\n",
      "Validation loss after itaration 2: 0.229468\n",
      "Time: 73m 50s\n",
      "\n",
      "Train loss after itaration 3: 0.193387\n",
      "Validation loss after itaration 3: 0.237963\n",
      "Time: 74m 3s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "num_mb_train = len(train_dataloader)\n",
    "num_mb_val = len(val_dataloader)\n",
    "\n",
    "if num_mb_val == 0:\n",
    "    num_mb_val = 1\n",
    "\n",
    "for n in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for k, (mb_x, mb_m, mb_y) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "        \n",
    "        mb_x = mb_x.to(device)\n",
    "        mb_m = mb_m.to(device)\n",
    "        mb_y = mb_y.to(device)\n",
    "        \n",
    "        outputs = model(mb_x, attention_mask=mb_m, labels=mb_y)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        #loss = model_loss(outputs[1], mb_y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        train_loss += loss.data / num_mb_train\n",
    "    \n",
    "    print (\"\\nTrain loss after itaration %i: %f\" % (n+1, train_loss))\n",
    "    train_losses.append(train_loss.cpu())\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        for k, (mb_x, mb_m, mb_y) in enumerate(val_dataloader):\n",
    "            mb_x = mb_x.to(device)\n",
    "            mb_m = mb_m.to(device)\n",
    "            mb_y = mb_y.to(device)\n",
    "        \n",
    "            outputs = model(mb_x, attention_mask=mb_m, labels=mb_y)\n",
    "            \n",
    "            loss = outputs[0]\n",
    "            #loss = model_loss(outputs[1], mb_y)\n",
    "            \n",
    "            val_loss += loss.data / num_mb_val\n",
    "            \n",
    "        print (\"Validation loss after itaration %i: %f\" % (n+1, val_loss))\n",
    "        val_losses.append(val_loss.cpu())\n",
    "    \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    print(f'Time: {epoch_mins}m {epoch_secs}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x178a402e0c8>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x178a88c4488>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "test_data = TensorDataset(test_x, test_m)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
    "\n",
    "outputs = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for k, (mb_x, mb_m) in enumerate(test_dataloader):\n",
    "        mb_x = mb_x.to(device)\n",
    "        mb_m = mb_m.to(device)\n",
    "        output = model(mb_x, attention_mask=mb_m)\n",
    "        outputs.append(output[0].to('cpu'))\n",
    "\n",
    "outputs = torch.cat(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted_values = torch.max(outputs, 1)\n",
    "predicted_values = predicted_values.numpy()\n",
    "true_values = test_y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9067127344521224\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = np.sum(predicted_values == true_values) / len(true_values)\n",
    "print (\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      3577\n",
      "           1       0.65      0.45      0.53       475\n",
      "\n",
      "    accuracy                           0.91      4052\n",
      "   macro avg       0.79      0.71      0.74      4052\n",
      "weighted avg       0.90      0.91      0.90      4052\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(true_values, predicted_values, target_names=[str(l) for l in label_values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
